{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Playing around with pathnames to get the hang of os.path functions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_path = os.path.expanduser(\"~/Danny/Administration/Finance/Haushaltsbudget/abrechnungen/credit\")\n",
    "debit_path = os.path.expanduser(\"~/Danny/Administration/Finance/Haushaltsbudget/abrechnungen/debit\")\n",
    "\n",
    "jan_cc_path = os.path.join(credit_path, \"544271XXXXXX1411_2022-01-01_2022-01-31-2.csv\")\n",
    "feb_cc_path = os.path.join(credit_path, \"544271XXXXXX1411_2022-02-01_2022-02-28.csv\")\n",
    "mar_cc_path = os.path.join(credit_path, \"544271XXXXXX1411_2022-03-01_2022-03-31.csv\")\n",
    "apr_cc_path = os.path.join(credit_path, \"544271XXXXXX1411_2022-04-01_2022-04-30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc_files = os.listdir(debit_path)\n",
    "jan_dc_file = [f for f in dc_files if \"01-01\" in f][0]\n",
    "jan_dc_path = os.path.join(debit_path, jan_dc_file)\n",
    "\n",
    "feb_dc_file = [f for f in dc_files if \"02-01\" in f][0]\n",
    "feb_dc_path = os.path.join(debit_path, feb_dc_file)\n",
    "\n",
    "mar_dc_file = [f for f in dc_files if \"03-01\" in f][0]\n",
    "mar_dc_path = os.path.join(debit_path, mar_dc_file)\n",
    "\n",
    "apr_dc_file = [f for f in dc_files if \"04-01\" in f][0]\n",
    "apr_dc_path = os.path.join(debit_path, apr_dc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Helpful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ...to import my bank statements (credit card and current account) and prepare them in a pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_statement(path_to_file):\n",
    "    \"\"\"\n",
    "    Reads in a csv_file with specific format (sep = \";\") and returns a cleaned list ready for pandas DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    with open(path_to_file, encoding = 'utf_16') as f:\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "    newLines = []\n",
    "    for i in range(len(lines)):\n",
    "        line = lines[i]\n",
    "        line = line.strip('\\n')\n",
    "#         line = line.replace(',', '.') # This is not good. If I have an amount larger than 1k, it will not parse\n",
    "# Try doing the , to . conversion within the pd.DataFrame already\n",
    "        line = line.split(';')\n",
    "        newLines.append(line)\n",
    "\n",
    "    return (newLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(lines):\n",
    "    \"\"\"\n",
    "    Returns a pd.DataFrame object from cleaned lines of bank statement\n",
    "    \"\"\"\n",
    "\n",
    "    nan_value = float(\"NaN\")\n",
    "    data = pd.DataFrame(data = lines[1:], columns = lines[0])\n",
    "    data[\"Betrag\"].replace('[.]', '', regex=True, inplace=True)\n",
    "    data[\"Betrag\"].replace('[,]', '.', regex=True, inplace=True)\n",
    "    data.replace(\"\", nan_value, inplace=True)\n",
    "    data.dropna(how='all', axis=1, inplace=True)\n",
    "    data[\"Betrag\"] = data[\"Betrag\"].astype(float)\n",
    "    data[\"Buchungs-Info\"] = data[\"Buchungs-Info\"].astype(str) # This is necessary so we don't have NaN as floats in this row, because we later work with this row assuming it contains only strings\n",
    "    data[\"Notiz\"] = data[\"Notiz\"].astype(str) # This is necessary so we don't have NaN as floats in this row, because we later work with this row assuming it contains only strings\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_entries(data):\n",
    "    data = data[~data.Notiz.apply(lambda s: \"ignore\" in s.lower())] # Remove entries flagged as ignored\n",
    "    data = data[~data.Notiz.apply(lambda s: \"gehalt\" in s.lower())] # Remove my salary\n",
    "    data = data[~data[\"Buchungs-Info\"].apply(lambda s: \"ihre zahlung vormonat\" in s.lower())] # Remove cc payment\n",
    "    data = data[~data[\"Buchungs-Info\"].apply(lambda s: \"kreditkartenrechnung\" in s.lower())] # Remove cc payment\n",
    "\n",
    "## In some cases I receive money back for shared or borrowed expenses. \n",
    "## In most cases I want to ignore those, but sometimes it's part of an expense that needs to stay visible\n",
    "## Then I don't want to ignore all positive values... Need to find a better (more fine-grained) solution here.\n",
    "\n",
    "    \n",
    "    data = data[~((data.Betrag >= 0) & (data.Notiz.apply(lambda s: s == \"nan\")))] # Remove all positive values, since I'm tracking spending only here\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing credit and debit card statements**\n",
    "\n",
    "- Read Lines from raw CSV\n",
    "- Clean lines and import into a data frame with appropriate data types in columns for filtering later\n",
    "- Logically filtering out entries (like removing ignored or positive entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_jan_cc = read_statement(jan_cc_path)\n",
    "jan_cc = clean_df(lines_jan_cc)\n",
    "jan_cc = filter_entries(jan_cc)\n",
    "\n",
    "lines_jan_dc = read_statement(jan_dc_path)\n",
    "jan_dc = clean_df(lines_jan_dc)\n",
    "jan_dc = filter_entries(jan_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_feb_cc = read_statement(feb_cc_path)\n",
    "feb_cc = clean_df(lines_feb_cc)\n",
    "feb_cc = filter_entries(feb_cc)\n",
    "\n",
    "lines_feb_dc = read_statement(feb_dc_path)\n",
    "feb_dc = clean_df(lines_feb_dc)\n",
    "feb_dc = filter_entries(feb_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_mar_cc = read_statement(mar_cc_path)\n",
    "mar_cc = clean_df(lines_mar_cc)\n",
    "mar_cc = filter_entries(mar_cc)\n",
    "\n",
    "lines_mar_dc = read_statement(mar_dc_path)\n",
    "mar_dc = clean_df(lines_mar_dc)\n",
    "mar_dc = filter_entries(mar_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valutadatum</th>\n",
       "      <th>Buchungsdatum</th>\n",
       "      <th>Partner Kontonummer</th>\n",
       "      <th>Bankleitzahl</th>\n",
       "      <th>Betrag</th>\n",
       "      <th>Währung</th>\n",
       "      <th>Buchungs-Info</th>\n",
       "      <th>Buchungsreferenz</th>\n",
       "      <th>Notiz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>11.03.2022</td>\n",
       "      <td>14.03.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>24.55</td>\n",
       "      <td>EUR</td>\n",
       "      <td>REV*roksh.com</td>\n",
       "      <td>201112203112ALV-004127892957</td>\n",
       "      <td>Hofer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>07.03.2022</td>\n",
       "      <td>08.03.2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>408.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Zuzahlung s Kreditkarte</td>\n",
       "      <td>201112203072ALV-141655481079</td>\n",
       "      <td>Ipad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Valutadatum Buchungsdatum Partner Kontonummer Bankleitzahl  Betrag Währung  \\\n",
       "39  11.03.2022    14.03.2022         40005195600        20111   24.55     EUR   \n",
       "54  07.03.2022    08.03.2022                 NaN          NaN  408.00     EUR   \n",
       "\n",
       "              Buchungs-Info              Buchungsreferenz  Notiz  \n",
       "39            REV*roksh.com  201112203112ALV-004127892957  Hofer  \n",
       "54  Zuzahlung s Kreditkarte  201112203072ALV-141655481079   Ipad  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mar_cc[((mar_cc.Betrag >= 0 ) & (mar_cc.Notiz.apply(lambda s: s != \"nan\")))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_apr_cc = read_statement(apr_cc_path)\n",
    "apr_cc = clean_df(lines_apr_cc)\n",
    "apr_cc = filter_entries(apr_cc)\n",
    "\n",
    "lines_apr_dc = read_statement(apr_dc_path)\n",
    "apr_dc = clean_df(lines_apr_dc)\n",
    "apr_dc = filter_entries(apr_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Valutadatum</th>\n",
       "      <th>Buchungsdatum</th>\n",
       "      <th>Partner Kontonummer</th>\n",
       "      <th>Bankleitzahl</th>\n",
       "      <th>Betrag</th>\n",
       "      <th>Währung</th>\n",
       "      <th>Buchungs-Info</th>\n",
       "      <th>Buchungsreferenz</th>\n",
       "      <th>Notiz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.04.2022</td>\n",
       "      <td>29.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Das Kafa</td>\n",
       "      <td>201112204282ALV-000901550689</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.04.2022</td>\n",
       "      <td>29.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-33.29</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Mjam Gmbh_llxp-hh07</td>\n",
       "      <td>201112204282ALV-000900027734</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.04.2022</td>\n",
       "      <td>29.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-9.80</td>\n",
       "      <td>EUR</td>\n",
       "      <td>NOODLE KING</td>\n",
       "      <td>201112204282ALV-000708363998</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.04.2022</td>\n",
       "      <td>28.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-8.14</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Hofer Dankt</td>\n",
       "      <td>201112204272ALV-234944448191</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.04.2022</td>\n",
       "      <td>28.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>EUR</td>\n",
       "      <td>BIPA dankt</td>\n",
       "      <td>201112204272ALV-234749096149</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26.04.2022</td>\n",
       "      <td>27.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-16.81</td>\n",
       "      <td>EUR</td>\n",
       "      <td>SPAR DANKT 4958</td>\n",
       "      <td>201112204262ALV-235259313998</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.04.2022</td>\n",
       "      <td>27.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-10.10</td>\n",
       "      <td>EUR</td>\n",
       "      <td>APOTHEKE Z ERZENGEL MI</td>\n",
       "      <td>201112204262ALV-235104873625</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.04.2022</td>\n",
       "      <td>27.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-3.65</td>\n",
       "      <td>EUR</td>\n",
       "      <td>APOTHEKE Z ERZENGEL MI</td>\n",
       "      <td>201112204262ALV-235104871853</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.04.2022</td>\n",
       "      <td>22.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Hofer Dankt</td>\n",
       "      <td>201112204212ALV-000239648588</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21.04.2022</td>\n",
       "      <td>22.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>O'CHICKEN NICE</td>\n",
       "      <td>201112204212ALV-000000048656</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.04.2022</td>\n",
       "      <td>22.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-9.60</td>\n",
       "      <td>EUR</td>\n",
       "      <td>SN3293000012841502</td>\n",
       "      <td>201112204212ALV-235939327392</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20.04.2022</td>\n",
       "      <td>21.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>OEBB Ticket</td>\n",
       "      <td>201112204202ALV-000222535752</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.04.2022</td>\n",
       "      <td>21.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-5.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>LES ETOILES ANTIBES</td>\n",
       "      <td>201112204202ALV-235943956003</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>20.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>O'CHICKEN NICE</td>\n",
       "      <td>201112204192ALV-233548118835</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>20.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-12.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>SC STUZZICO</td>\n",
       "      <td>201112204192ALV-233548007414</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>20.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-17.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>PLAGE HELIOS</td>\n",
       "      <td>201112204192ALV-233548006453</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>20.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-9.80</td>\n",
       "      <td>EUR</td>\n",
       "      <td>SNCF</td>\n",
       "      <td>201112204192ALV-233547216163</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-9.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>ABORD 1</td>\n",
       "      <td>201112204182ALV-235009017259</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-147.20</td>\n",
       "      <td>EUR</td>\n",
       "      <td>PALOMA</td>\n",
       "      <td>201112204182ALV-234859003140</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-28.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>LE BULL DOG</td>\n",
       "      <td>201112204182ALV-234858967364</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-22.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>COUP DE SOLEIL</td>\n",
       "      <td>201112204182ALV-234858934180</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>18.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-13.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>MAT</td>\n",
       "      <td>201112204182ALV-234858844799</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>18.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-79.60</td>\n",
       "      <td>EUR</td>\n",
       "      <td>CAFE DE LA PLAC</td>\n",
       "      <td>201112204182ALV-234858806596</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>18.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-20.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>SC SARL VENUS</td>\n",
       "      <td>201112204182ALV-234858712332</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-1.85</td>\n",
       "      <td>EUR</td>\n",
       "      <td>LA BOULANGERIE</td>\n",
       "      <td>201112204182ALV-234847644739</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-21.40</td>\n",
       "      <td>EUR</td>\n",
       "      <td>LE PASTROUIL</td>\n",
       "      <td>201112204162ALV-235528853732</td>\n",
       "      <td>nice-food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>OEBB Ticket</td>\n",
       "      <td>201112204162ALV-235321839737</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Fladerei</td>\n",
       "      <td>201112204152ALV-002434471310</td>\n",
       "      <td>lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.04.2022</td>\n",
       "      <td>19.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Ströck 3084 Berggasse</td>\n",
       "      <td>201112204152ALV-002246429247</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14.04.2022</td>\n",
       "      <td>15.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-4.50</td>\n",
       "      <td>EUR</td>\n",
       "      <td>BEI NINO</td>\n",
       "      <td>201112204142ALV-001549422288</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13.04.2022</td>\n",
       "      <td>14.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>EUR</td>\n",
       "      <td>ARWAG-Ob. Donaustr.21/</td>\n",
       "      <td>201112204132ALV-001438973919</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.04.2022</td>\n",
       "      <td>13.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>EUR</td>\n",
       "      <td>ARWAG-Ob. Donaustr.21/</td>\n",
       "      <td>201112204122ALV-001915840282</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.04.2022</td>\n",
       "      <td>13.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>EUR</td>\n",
       "      <td>ARWAG-Ob. Donaustr.21/</td>\n",
       "      <td>201112204122ALV-001915838580</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.04.2022</td>\n",
       "      <td>13.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>EUR</td>\n",
       "      <td>ARWAG-Ob. Donaustr.21/</td>\n",
       "      <td>201112204122ALV-001915721791</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12.04.2022</td>\n",
       "      <td>13.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>EUR</td>\n",
       "      <td>ARWAG-Ob. Donaustr.21/</td>\n",
       "      <td>201112204122ALV-001915720192</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12.04.2022</td>\n",
       "      <td>13.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>EUR</td>\n",
       "      <td>ARWAG-Ob. Donaustr.21/</td>\n",
       "      <td>201112204122ALV-001915717905</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>12.04.2022</td>\n",
       "      <td>13.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>EUR</td>\n",
       "      <td>UNI-ECK IMBISS KG</td>\n",
       "      <td>201112204122ALV-001545627714</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10.04.2022</td>\n",
       "      <td>11.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-40.57</td>\n",
       "      <td>EUR</td>\n",
       "      <td>BILLA dankt</td>\n",
       "      <td>201112204102ALV-231733446906</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10.04.2022</td>\n",
       "      <td>11.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-10.12</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Hofer Dankt</td>\n",
       "      <td>201112204102ALV-231611276657</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>09.04.2022</td>\n",
       "      <td>11.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-4.42</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Hofer Dankt</td>\n",
       "      <td>201112204092ALV-235921288036</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>06.04.2022</td>\n",
       "      <td>07.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-0.69</td>\n",
       "      <td>EUR</td>\n",
       "      <td>SPAR DANKT 4823</td>\n",
       "      <td>201112204062ALV-235302703316</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>06.04.2022</td>\n",
       "      <td>07.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-40.34</td>\n",
       "      <td>EUR</td>\n",
       "      <td>AMZN MKTP DE*293HS12O4</td>\n",
       "      <td>201112204062ALV-235112061071</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>05.04.2022</td>\n",
       "      <td>06.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-11.97</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Hofer Dankt</td>\n",
       "      <td>201112204052ALV-000703250448</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>03.04.2022</td>\n",
       "      <td>04.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-48.16</td>\n",
       "      <td>EUR</td>\n",
       "      <td>PENNY dankt</td>\n",
       "      <td>201112204032ALV-231326285124</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>02.04.2022</td>\n",
       "      <td>04.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-3.10</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Ströck 3055 Nußdorfer</td>\n",
       "      <td>201112204022ALV-235308603606</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>02.04.2022</td>\n",
       "      <td>04.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-6.90</td>\n",
       "      <td>EUR</td>\n",
       "      <td>SwingKitchen Store006</td>\n",
       "      <td>201112204022ALV-235307825319</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>02.04.2022</td>\n",
       "      <td>04.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-3.58</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Hofer Dankt</td>\n",
       "      <td>201112204022ALV-235114658197</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>02.04.2022</td>\n",
       "      <td>04.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-7.60</td>\n",
       "      <td>EUR</td>\n",
       "      <td>SN3293000012758005</td>\n",
       "      <td>201112204022ALV-235104496505</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>01.04.2022</td>\n",
       "      <td>04.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-6.40</td>\n",
       "      <td>EUR</td>\n",
       "      <td>UNI-ECK IMBISS KG</td>\n",
       "      <td>201112204012ALV-000547516538</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>01.04.2022</td>\n",
       "      <td>04.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-32.00</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Hairstyling Gruppa L'U</td>\n",
       "      <td>201112204012ALV-000529609212</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>01.04.2022</td>\n",
       "      <td>04.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-2.35</td>\n",
       "      <td>EUR</td>\n",
       "      <td>TIER AT 3-141273</td>\n",
       "      <td>201112204012ALV-000452415504</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>31.03.2022</td>\n",
       "      <td>01.04.2022</td>\n",
       "      <td>40005195600</td>\n",
       "      <td>20111</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>EUR</td>\n",
       "      <td>Hofer Dankt</td>\n",
       "      <td>201112203312ALV-233840901690</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Valutadatum Buchungsdatum Partner Kontonummer Bankleitzahl  Betrag Währung  \\\n",
       "0   28.04.2022    29.04.2022         40005195600        20111   -3.60     EUR   \n",
       "1   28.04.2022    29.04.2022         40005195600        20111  -33.29     EUR   \n",
       "2   28.04.2022    29.04.2022         40005195600        20111   -9.80     EUR   \n",
       "3   27.04.2022    28.04.2022         40005195600        20111   -8.14     EUR   \n",
       "4   27.04.2022    28.04.2022         40005195600        20111   -1.95     EUR   \n",
       "5   26.04.2022    27.04.2022         40005195600        20111  -16.81     EUR   \n",
       "6   26.04.2022    27.04.2022         40005195600        20111  -10.10     EUR   \n",
       "7   26.04.2022    27.04.2022         40005195600        20111   -3.65     EUR   \n",
       "8   21.04.2022    22.04.2022         40005195600        20111   -0.91     EUR   \n",
       "9   21.04.2022    22.04.2022         40005195600        20111   -7.00     EUR   \n",
       "10  21.04.2022    22.04.2022         40005195600        20111   -9.60     EUR   \n",
       "11  20.04.2022    21.04.2022         40005195600        20111   -1.90     EUR   \n",
       "12  20.04.2022    21.04.2022         40005195600        20111   -5.90     EUR   \n",
       "13  19.04.2022    20.04.2022         40005195600        20111   -7.00     EUR   \n",
       "14  19.04.2022    20.04.2022         40005195600        20111  -12.00     EUR   \n",
       "15  19.04.2022    20.04.2022         40005195600        20111  -17.00     EUR   \n",
       "16  19.04.2022    20.04.2022         40005195600        20111   -9.80     EUR   \n",
       "17  18.04.2022    19.04.2022         40005195600        20111   -9.00     EUR   \n",
       "18  18.04.2022    19.04.2022         40005195600        20111 -147.20     EUR   \n",
       "19  18.04.2022    19.04.2022         40005195600        20111  -28.00     EUR   \n",
       "20  18.04.2022    19.04.2022         40005195600        20111  -22.00     EUR   \n",
       "21  18.04.2022    19.04.2022         40005195600        20111  -13.90     EUR   \n",
       "22  18.04.2022    19.04.2022         40005195600        20111  -79.60     EUR   \n",
       "23  18.04.2022    19.04.2022         40005195600        20111  -20.00     EUR   \n",
       "24  18.04.2022    19.04.2022         40005195600        20111   -1.85     EUR   \n",
       "25  16.04.2022    19.04.2022         40005195600        20111  -21.40     EUR   \n",
       "26  16.04.2022    19.04.2022         40005195600        20111   -1.90     EUR   \n",
       "27  15.04.2022    19.04.2022         40005195600        20111   -6.40     EUR   \n",
       "28  15.04.2022    19.04.2022         40005195600        20111   -3.10     EUR   \n",
       "29  14.04.2022    15.04.2022         40005195600        20111   -4.50     EUR   \n",
       "30  13.04.2022    14.04.2022         40005195600        20111   -0.50     EUR   \n",
       "31  12.04.2022    13.04.2022         40005195600        20111   -0.50     EUR   \n",
       "32  12.04.2022    13.04.2022         40005195600        20111   -0.50     EUR   \n",
       "33  12.04.2022    13.04.2022         40005195600        20111   -0.50     EUR   \n",
       "34  12.04.2022    13.04.2022         40005195600        20111   -0.50     EUR   \n",
       "35  12.04.2022    13.04.2022         40005195600        20111   -0.50     EUR   \n",
       "36  12.04.2022    13.04.2022         40005195600        20111   -6.40     EUR   \n",
       "37  10.04.2022    11.04.2022         40005195600        20111  -40.57     EUR   \n",
       "38  10.04.2022    11.04.2022         40005195600        20111  -10.12     EUR   \n",
       "39  09.04.2022    11.04.2022         40005195600        20111   -4.42     EUR   \n",
       "40  06.04.2022    07.04.2022         40005195600        20111   -0.69     EUR   \n",
       "41  06.04.2022    07.04.2022         40005195600        20111  -40.34     EUR   \n",
       "42  05.04.2022    06.04.2022         40005195600        20111  -11.97     EUR   \n",
       "44  03.04.2022    04.04.2022         40005195600        20111  -48.16     EUR   \n",
       "45  02.04.2022    04.04.2022         40005195600        20111   -3.10     EUR   \n",
       "46  02.04.2022    04.04.2022         40005195600        20111   -6.90     EUR   \n",
       "47  02.04.2022    04.04.2022         40005195600        20111   -3.58     EUR   \n",
       "48  02.04.2022    04.04.2022         40005195600        20111   -7.60     EUR   \n",
       "50  01.04.2022    04.04.2022         40005195600        20111   -6.40     EUR   \n",
       "51  01.04.2022    04.04.2022         40005195600        20111  -32.00     EUR   \n",
       "52  01.04.2022    04.04.2022         40005195600        20111   -2.35     EUR   \n",
       "53  31.03.2022    01.04.2022         40005195600        20111   -7.62     EUR   \n",
       "\n",
       "             Buchungs-Info              Buchungsreferenz        Notiz  \n",
       "0                 Das Kafa  201112204282ALV-000901550689          nan  \n",
       "1      Mjam Gmbh_llxp-hh07  201112204282ALV-000900027734          nan  \n",
       "2              NOODLE KING  201112204282ALV-000708363998          nan  \n",
       "3              Hofer Dankt  201112204272ALV-234944448191          nan  \n",
       "4               BIPA dankt  201112204272ALV-234749096149          nan  \n",
       "5          SPAR DANKT 4958  201112204262ALV-235259313998          nan  \n",
       "6   APOTHEKE Z ERZENGEL MI  201112204262ALV-235104873625          nan  \n",
       "7   APOTHEKE Z ERZENGEL MI  201112204262ALV-235104871853          nan  \n",
       "8              Hofer Dankt  201112204212ALV-000239648588          nan  \n",
       "9           O'CHICKEN NICE  201112204212ALV-000000048656    nice-food  \n",
       "10      SN3293000012841502  201112204212ALV-235939327392          nan  \n",
       "11             OEBB Ticket  201112204202ALV-000222535752          nan  \n",
       "12     LES ETOILES ANTIBES  201112204202ALV-235943956003    nice-food  \n",
       "13          O'CHICKEN NICE  201112204192ALV-233548118835    nice-food  \n",
       "14             SC STUZZICO  201112204192ALV-233548007414    nice-food  \n",
       "15            PLAGE HELIOS  201112204192ALV-233548006453    nice-food  \n",
       "16                    SNCF  201112204192ALV-233547216163    nice-food  \n",
       "17                 ABORD 1  201112204182ALV-235009017259    nice-food  \n",
       "18                  PALOMA  201112204182ALV-234859003140    nice-food  \n",
       "19             LE BULL DOG  201112204182ALV-234858967364    nice-food  \n",
       "20          COUP DE SOLEIL  201112204182ALV-234858934180    nice-food  \n",
       "21                     MAT  201112204182ALV-234858844799    nice-food  \n",
       "22         CAFE DE LA PLAC  201112204182ALV-234858806596    nice-food  \n",
       "23           SC SARL VENUS  201112204182ALV-234858712332    nice-food  \n",
       "24          LA BOULANGERIE  201112204182ALV-234847644739    nice-food  \n",
       "25            LE PASTROUIL  201112204162ALV-235528853732    nice-food  \n",
       "26             OEBB Ticket  201112204162ALV-235321839737          nan  \n",
       "27                Fladerei  201112204152ALV-002434471310        lunch  \n",
       "28   Ströck 3084 Berggasse  201112204152ALV-002246429247          nan  \n",
       "29                BEI NINO  201112204142ALV-001549422288          nan  \n",
       "30  ARWAG-Ob. Donaustr.21/  201112204132ALV-001438973919          nan  \n",
       "31  ARWAG-Ob. Donaustr.21/  201112204122ALV-001915840282          nan  \n",
       "32  ARWAG-Ob. Donaustr.21/  201112204122ALV-001915838580          nan  \n",
       "33  ARWAG-Ob. Donaustr.21/  201112204122ALV-001915721791          nan  \n",
       "34  ARWAG-Ob. Donaustr.21/  201112204122ALV-001915720192          nan  \n",
       "35  ARWAG-Ob. Donaustr.21/  201112204122ALV-001915717905          nan  \n",
       "36       UNI-ECK IMBISS KG  201112204122ALV-001545627714          nan  \n",
       "37             BILLA dankt  201112204102ALV-231733446906          nan  \n",
       "38             Hofer Dankt  201112204102ALV-231611276657          nan  \n",
       "39             Hofer Dankt  201112204092ALV-235921288036          nan  \n",
       "40         SPAR DANKT 4823  201112204062ALV-235302703316          nan  \n",
       "41  AMZN MKTP DE*293HS12O4  201112204062ALV-235112061071  electronics  \n",
       "42             Hofer Dankt  201112204052ALV-000703250448          nan  \n",
       "44             PENNY dankt  201112204032ALV-231326285124          nan  \n",
       "45   Ströck 3055 Nußdorfer  201112204022ALV-235308603606          nan  \n",
       "46   SwingKitchen Store006  201112204022ALV-235307825319          nan  \n",
       "47             Hofer Dankt  201112204022ALV-235114658197          nan  \n",
       "48      SN3293000012758005  201112204022ALV-235104496505          nan  \n",
       "50       UNI-ECK IMBISS KG  201112204012ALV-000547516538          nan  \n",
       "51  Hairstyling Gruppa L'U  201112204012ALV-000529609212          nan  \n",
       "52        TIER AT 3-141273  201112204012ALV-000452415504          nan  \n",
       "53             Hofer Dankt  201112203312ALV-233840901690          nan  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apr_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining categories which I have in by budget**\n",
    "\n",
    "This doesn't happen yet because, what I'm actually searching for in my statements are **items**, which I have in sub-categories.\n",
    "\n",
    "If I want to have the higher level categories, I still need to connect the categorised items to their respective categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\"Living Costs\": [\"Rent\", \"Laundry\", \"Household\"], \n",
    "              \"Transport\": [\"Jahreskarte\", \"Parking\", \"Scooter\", \"Uber\", \"ShareNow\", \"Public Transport\"],\n",
    "              \"Food\": [\"Groceries\", \"Eating Out\", \"Breakfast\", \"Lunch\"],\n",
    "              \"Leisure\": [\"Coffee\", \"Alcohol\", \"Activity\"],\n",
    "              \"Health/Beauty\": [\"Hygiene\", \"Lenses\", \"Hair\", \"Pharma\"],\n",
    "              \"Subscriptions\": [\"Spotify\", \"Phone\"],\n",
    "              \"Shopping\": [\"Clothes\", \"Electronics\"],\n",
    "              \"Sports\": [\"Tennis\", \"Sports\"],\n",
    "              \"Contingency\": [\"Uncategorised\", \"Admin\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = {\n",
    "    \"Rent\": [\"Miete\"],\n",
    "    \"Household\": [\"Household\"],\n",
    "    \"Laundry\": [\"Laundry, ARWAG\"],\n",
    "    \"Groceries\": [\"Groceries\", \"BILLA\", \"SPAR\", \"Hofer\", \"Penny\"],\n",
    "    \"Hair\": [\"Hair\"],\n",
    "    \"Hygiene\": [\"Hygiene\", \"BIPA\"],\n",
    "    \"Lenses\": [\"Lenses\", \"VOLENS\"],\n",
    "    \"Pharma\": [\"Apotheke\", \"Pharma\"],\n",
    "    \"Eating Out\": [\"Eating Out\", \"Pumpui\", \"Aumann\", \"McDonalds\", \"Mjam\", \"PIZZERIA\"], #Need Note here\n",
    "    \"Breakfast\": [\"Breakfast\", \"Der Mann\", \"NOEBAUER\", \"Ströck\"], #Need Note here\n",
    "    \"Lunch\": [\"Lunch\", \"UNI-ECK\", \"NINO\", \"Noodle King\", \"Swingkitchen\"], #Need Note here\n",
    "    \"Scooter\": [\"Scooter\", \"TIER\", \"LIM\"],\n",
    "    \"Uber\": [\"Uber\", \"UBER\"],\n",
    "    \"ShareNow\": [\"ShareNow\", \"SN329\"],\n",
    "    \"Sports\": [\"Sports\"],\n",
    "    \"Spotify\": [\"Spotify Fam\"],\n",
    "    \"Phone\": [\"XOXO\"],\n",
    "    \"Public Transport\": [\"OEBB\", ],\n",
    "    \"Alcohol\": [\"alcohol\", \"NEEDLE\", \"PICKWICKS\", ], #Need Note here\n",
    "    \"Activity\": [\"Activity\", \"NTRY\"],  #Need Note here\n",
    "    \"Uncategorised\": [\"Uncategorised\"],\n",
    "    \"Admin\": [\"Admin\"],\n",
    "    \"Tennis\": [\"Tennis\"],\n",
    "    \"Laundry\": [\"Laundry\", \"ARWAG\"],\n",
    "    \"Coffee\": [\"Coffee\", \"Kafa\", ],\n",
    "    \"Shopping\": [\"Shopping\", \"electronics\", \"gifts\", \"clothes\"],\n",
    "    \"Contingency\": [\"ipad\"],\n",
    "    \"vacations\": [\"nice-food\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining function, which takes a string (Buchungs-Info or Notiz) and checks whether that string contains some item name**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_item_category(s, item_category):\n",
    "    candidates = items[item_category]\n",
    "    for candidate in candidates:\n",
    "        if candidate.lower() in s.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notiz_is_category(s, item_category):\n",
    "    candidates = categories.values()\n",
    "    for candidate in candidates:\n",
    "        if candidate.lower() in s.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the function which does the categorising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_statement(data, month):\n",
    "\n",
    "    categorised_data = pd.DataFrame(columns = [\"item\", \"amount\"])\n",
    "    \n",
    "    print()\n",
    "    print ('{} expenses:'.format(month))\n",
    "    tot_sum = 0\n",
    "    n_items = 0\n",
    "    tot_items = len(data)\n",
    "    remaining_items = data\n",
    "    \n",
    "#     for candidates in categories.values():\n",
    "#         for item in candidates:\n",
    "\n",
    "#             if len(found_entries) == 0: continue\n",
    "\n",
    "#             sum_item_category = round(found_entries[\"Betrag\"].sum(), 2)\n",
    "#             print(item, \": \", sum_item_category)\n",
    "#             tot_sum += sum_item_category\n",
    "#             n_items += len(found_entries)\n",
    "#             remaining_items = remaining_items[~remaining_items[\"Notiz\"].apply(lambda s: item in s)]\n",
    "\n",
    "#             new_line = pd.DataFrame({\"item\": item, \"amount\" : -sum_item_category}, index = [0])\n",
    "#             categorised_data = pd.concat([categorised_data, new_line],  ignore_index=True)\n",
    "    \n",
    "    for item_category in items.keys():\n",
    "        try:\n",
    "            found_entries_items = remaining_items[remaining_items[\"Buchungs-Info\"].apply(lambda x: is_item_category(x, item_category))]\n",
    "            remaining_items = remaining_items[~remaining_items[\"Buchungs-Info\"].apply(lambda x: is_item_category(x, item_category))]\n",
    "            found_entries_notiz = remaining_items[remaining_items[\"Notiz\"].apply(lambda s: is_item_category(s, item_category))]\n",
    "            remaining_items = remaining_items[~remaining_items[\"Notiz\"].apply(lambda s: is_item_category(s, item_category))]\n",
    "        except KeyError:\n",
    "            break\n",
    "        if len(found_entries_items) == 0 and len(found_entries_notiz) == 0: continue\n",
    "\n",
    "        found_entries = pd.concat([found_entries_items, found_entries_notiz]).drop_duplicates()\n",
    "        \n",
    "        sum_item_category = round(found_entries[\"Betrag\"].sum(), 2)\n",
    "        print(item_category, \": \", sum_item_category)\n",
    "        tot_sum += sum_item_category\n",
    "        n_items += len(found_entries)\n",
    "        remaining_items = remaining_items[~remaining_items[\"Buchungs-Info\"].apply(lambda x: is_item_category(x, item_category))]\n",
    "\n",
    "        if item_category in categorised_data.item:\n",
    "            categorised_data[categorised_data.item == item_category][\"amount\"] = categorised_data[categorised_data.item == item_category][\"amount\"] + sum_item_category\n",
    "        else:\n",
    "            new_line = pd.DataFrame({\"item\": item_category, \"amount\" : -sum_item_category}, index = [0])\n",
    "            categorised_data = pd.concat([categorised_data, new_line], ignore_index=True)\n",
    "        \n",
    "    print(\"-------------------------------------\")\n",
    "    print (\"Categorised {} items from {}\".format(n_items, tot_items))\n",
    "    print (\"Total: \", round(tot_sum, 2))\n",
    "\n",
    "    print(\"-------------------------------------\")\n",
    "    print (\"Uncategorised Items: \", tot_items - n_items, \" with total of: \", round(data[\"Betrag\"].sum() - tot_sum, 2), \"\\n\")\n",
    "    if len(remaining_items) > 0 :\n",
    "        print (remaining_items[[\"Buchungsdatum\", \"Betrag\", \"Buchungs-Info\", \"Notiz\"]])\n",
    "    \n",
    "    return categorised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "January expenses:\n",
      "Groceries :  -74.41\n",
      "Eating Out :  -119.9\n",
      "Breakfast :  -16.5\n",
      "Lunch :  -94.5\n",
      "Scooter :  -14.07\n",
      "Uber :  -10.23\n",
      "Spotify :  -2.5\n",
      "Phone :  -13.22\n",
      "Public Transport :  -5.0\n",
      "Alcohol :  -57.0\n",
      "Activity :  -49.76\n",
      "Uncategorised :  -84.5\n",
      "-------------------------------------\n",
      "Categorised 41 items from 41\n",
      "Total:  -541.59\n",
      "-------------------------------------\n",
      "Uncategorised Items:  0  with total of:  0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "jan_data = pd.concat([jan_cc, jan_dc], ignore_index=True)\n",
    "\n",
    "jan_data_eval = evaluate_statement(jan_data, \"January\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_data_eval.to_csv(\"jan_data_evaluated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Febuary expenses:\n",
      "Rent :  -825.0\n",
      "Household :  -12.35\n",
      "Laundry :  -4.5\n",
      "Groceries :  -189.28\n",
      "Hygiene :  -51.7\n",
      "Eating Out :  -68.42\n",
      "Breakfast :  -5.35\n",
      "Lunch :  -48.4\n",
      "Scooter :  -4.75\n",
      "Uber :  -21.8\n",
      "ShareNow :  -10.06\n",
      "Spotify :  -2.5\n",
      "Phone :  -9.97\n",
      "Alcohol :  -192.0\n",
      "Activity :  -60.0\n",
      "Admin :  -20.7\n",
      "Tennis :  -130.0\n",
      "Coffee :  -17.65\n",
      "-------------------------------------\n",
      "Categorised 78 items from 80\n",
      "Total:  -1674.43\n",
      "-------------------------------------\n",
      "Uncategorised Items:  2  with total of:  864.59 \n",
      "\n",
      "   Buchungsdatum  Betrag            Buchungs-Info                  Notiz\n",
      "14    23.02.2022  556.62  Zuzahlung s Kreditkarte  Geld für MacBook Kauf\n",
      "2     24.02.2022  307.97        Sent from Revolut           Nice Freddie\n"
     ]
    }
   ],
   "source": [
    "feb_data = pd.concat([feb_cc, feb_dc])\n",
    "\n",
    "feb_data_eval = evaluate_statement(feb_data, \"Febuary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "feb_data_eval.to_csv(\"feb_data_evaluated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "March expenses:\n",
      "Rent :  -625.0\n",
      "Laundry :  -5.5\n",
      "Groceries :  -277.84\n",
      "Hygiene :  -4.99\n",
      "Lenses :  -64.89\n",
      "Pharma :  -10.1\n",
      "Eating Out :  -19.0\n",
      "Breakfast :  -7.9\n",
      "Lunch :  -114.9\n",
      "Scooter :  -13.93\n",
      "ShareNow :  -16.77\n",
      "Sports :  -32.86\n",
      "Spotify :  -2.5\n",
      "Phone :  -9.98\n",
      "Alcohol :  -40.5\n",
      "Activity :  -80.0\n",
      "Tennis :  -171.43\n",
      "Coffee :  -14.3\n",
      "Shopping :  -83.23\n",
      "Contingency :  -507.98\n",
      "-------------------------------------\n",
      "Categorised 76 items from 76\n",
      "Total:  -2103.6\n",
      "-------------------------------------\n",
      "Uncategorised Items:  0  with total of:  0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mar_data = pd.concat([mar_cc, mar_dc])\n",
    "\n",
    "mar_data_eval = evaluate_statement(mar_data, \"March\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "mar_data_eval.to_csv(\"mar_data_evaluated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "April expenses:\n",
      "Rent :  -625.0\n",
      "Laundry :  -3.0\n",
      "Groceries :  -202.99\n",
      "Hair :  -32.0\n",
      "Hygiene :  -1.95\n",
      "Pharma :  -13.75\n",
      "Eating Out :  -33.29\n",
      "Breakfast :  -6.2\n",
      "Lunch :  -75.4\n",
      "Scooter :  -4.55\n",
      "ShareNow :  -17.2\n",
      "Spotify :  -2.5\n",
      "Phone :  -9.98\n",
      "Public Transport :  -3.8\n",
      "Alcohol :  -20.0\n",
      "Coffee :  -3.6\n",
      "Shopping :  -40.34\n",
      "vacations :  -401.65\n",
      "-------------------------------------\n",
      "Categorised 62 items from 62\n",
      "Total:  -1497.2\n",
      "-------------------------------------\n",
      "Uncategorised Items:  0  with total of:  -0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "apr_data = pd.concat([apr_cc, apr_dc])\n",
    "\n",
    "apr_data_eval = evaluate_statement(apr_data, \"April\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "apr_data_eval.to_csv(\"apr_data_evaluated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First check Notiz for category name\n",
    "# Then check Buchungs-Info for items which can lead to category via items and categories dicts\n",
    "# Finally (via gui, eventually) print entries where no category was found and ask for category\n",
    "# If no category is given, put in uncategorised \n",
    "\n",
    "# For some entries (where I paid for others or when I get money back), I will either have to ignore them or\n",
    "# Consolidate them. In particular, if I get money back from several people put it all together and create\n",
    "# Effective entries of the money I actually spent. Since this is still a review process, I need to find a GUI way\n",
    "# To implement this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some entries (where I paid for others or when I get money back), I will either have to ignore them or\n",
    "Consolidate them. In particular, if I get money back from several people put it all together and create\n",
    "Effective entries of the money I actually spent. Since this is still a review process, I need to find a GUI way\n",
    "To implement this\n",
    "\n",
    "My thought is that for every entry that doesn't have a category I either set a category or I can remove/create a new entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
